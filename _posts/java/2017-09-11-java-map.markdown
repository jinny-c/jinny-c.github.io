---
layout: category
title:  "HashTable和HashMap"
description: HashTable和HashMap的区别详解。
categories: java
#categories: [java, map, hashMap]
preview: /static/images/common/150/54.jpg
---


### 1. HashMap简介

　　`HashMap`是基于哈希表实现的，每一个元素是一个`key-value`对，其内部通过单链表解决冲突问题，容量不足（超过了阀值）时，同样会自动增长。  
　　`HashMap`是非线程安全的，只是用于单线程环境下，多线程环境下可以采用`concurrent`并发包下的`concurrentHashMap`。  
　　`HashMap` 实现了`Serializable`接口，因此它支持序列化，实现了`Cloneable`接口，能被克隆。  
**`HashMap`存数据的过程是：**
>　　`HashMap`内部维护了一个存储数据的`Entry`数组，`HashMap`采用链表解决冲突，每一个`Entry`本质上是一个单向链表。  
　　当准备添加一个`key-value`对时，首先通过`hash(key)`方法计算`hash`值，然后通过`indexFor(hash,length)`求该`key-value`对的存储位置，
计算方法是先用`hash&0x7FFFFFFF`后，再对`length`取模，这就保证每一个`key-value`对都能存入`HashMap`中，当计算出的位置相同时，由于存入位置是一个链表，则把这个`key-value对`插入链表头。  
　　`HashMap`中`key`和`value`都允许为`null`。`key`为`null`的键值对永远都放在以`table[0]`为头结点的链表中。  

了解了数据的存储，那么数据的读取也就很容易就明白了。  
**`HashMap`的存储结构，如下图所示：**  
![HashMap的存储结构](/static/images/src/hashMap.jpg)

　　图中，紫色部分即代表哈希表，也称为哈希数组，数组的每个元素都是一个单链表的头节点，链表是用来解决冲突的，如果不同的key映射到了数组的同一位置处，就将其放入单链表中。  
　　`HashMap`内存储数据的`Entry`数组默认是`16`，如果没有对`Entry`扩容机制的话，当存储的数据一多，`Entry`内部的链表会很长，这就失去了`HashMap`的存储意义了。所以`HasnMap`内部有自己的扩容机制。  

>**HashMap内部有：**  
　　变量`size`，它记录`HashMap`的底层数组中已用槽的数量；  
　　变量`threshold`，它是`HashMap`的阈值，用于判断是否需要调整`HashMap`的容量（`threshold = 容量*加载因子`）    
　　变量`DEFAULT_LOAD_FACTOR = 0.75f`，默认加载因子为`0.75`  
**`HashMap`扩容的条件是：**   
　　当`size`大于`threshold`时，对`HashMap`进行扩容    
　　扩容是新建了一个`HashMap`的底层数组，而后调用`transfer`方法，将`旧HashMap`的全部元素添加到`新的HashMap`中（要重新计算元素在新的数组中的索引位置）。  
　　很明显，扩容是一个相当耗时的操作，因为它需要重新计算这些元素在新的数组中的位置并进行复制处理。因此，我们在用`HashMap`的时，最好能提前预估下`HashMap`中元素的个数，这样有助于提高`HashMap`的性能。  
　　`HashMap`共有四个构造方法。构造方法中提到了两个很重要的参数：*初始容量和加载因子*。这两个参数是影响`HashMap`性能的重要参数，
其中`容量`表示哈希表中槽的数量（即哈希数组的长度），`初始容量`是创建哈希表时的容量（从构造函数中可以看出，如果不指明，则默认为`16`），
`加载因子`是哈希表在其容量自动增加之前可以达到多满的一种尺度，当哈希表中的条目数超出了加载因子与当前容量的乘积时，则要对该哈希表进行 `resize` 操作（即扩容）。  
**下面说下加载因子，**  
　　如果加载因子越大，对空间的利用更充分，但是查找效率会降低（链表长度会越来越长）；  
　　如果加载因子太小，那么表中的数据将过于稀疏（很多空间还没用，就开始扩容了），对空间造成严重浪费。  
　　如果我们在构造方法中不指定，则系统默认加载因子为`0.75`，这是一个比较理想的值，一般情况下我们是无需修改的。  
　　另外，无论我们指定的容量为多少，构造方法都会将实际容量设为不小于指定容量的`2的次方`的一个数，且最大值不能超过`2的30次方`

　　对`HashMap`想进一步深入了解的朋友推荐看一下`HashMap`源码剖析：<http://blog.csdn.net/ns_code/article/details/36034955>

### 2. Hashtable简介
　　`Hashtable`同样是基于哈希表实现的，同样每个元素是一个`key-value`对，其内部也是通过单链表解决冲突问题，容量不足（超过了阀值）时，同样会自动增长。  
　　`Hashtable`也是`JDK1.0`引入的类，是线程安全的，能用于多线程环境中。  
　　`Hashtable`同样实现了`Serializable`接口，它支持序列化，实现了`Cloneable`接口，能被克隆。

　　`Hashtable`和`HashMap`比较相似，感兴趣的朋友可以看“Hashtable源码剖析”这篇博客：<http://blog.csdn.net/ns_code/article/details/36191279>

## 下面主要介绍一下HashTable和HashMap区别
### 3. HashTable和HashMap区别
　　1. 继承的父类不同  
　　`Hashtable`继承自`Dictionary`类，而`HashMap`继承自`AbstractMap`类。但二者都实现了`Map`接口。  
　　2. 线程安全性不同  
　　`javadoc`中关于`hashmap`的一段描述如下：此实现不是同步的。如果多个线程同时访问一个哈希映射，而其中至少一个线程从结构上修改了该映射，则它必须保持外部同步。  
　　`Hashtable` 中的方法是`Synchronize`的，而`HashMap`中的方法在缺省情况下是非`Synchronize`的。在多线程并发的环境下，可以直接使用`Hashtable`，
不需要自己为它的方法实现同步，但使用`HashMap`时就必须要自己增加同步处理。（结构上的修改是指添加或删除一个或多个映射关系的任何操作；仅改变与实例已经包含的键关联的值不是结构上的修改。）
这一般通过对自然封装该映射的对象进行同步操作来完成。如果不存在这样的对象，则应该使用` Collections.synchronizedMap` 方法来“包装”该映射。  
最好在创建时完成这一操作，以防止对映射进行意外的非同步访问，如下所示：
````java
  Map m = Collections.synchronizedMap(new HashMap(...));
````
　　`Hashtable` 线程安全很好理解，因为它每个方法中都加入了`Synchronize`。  
　　`HashMap`底层是一个`Entry`数组，当发生`hash`冲突的时候，`hashmap`是采用链表的方式来解决的，在对应的数组位置存放链表的头结点。对链表而言，新加入的节点会从头结点加入。

**我们可以得到第四个不同的地方**

#### 1. `key`和`value`是否允许`null`值
　　其中`key`和`value`都是对象，并且不能包含重复`key`，但可以包含重复的`value`。  
　　通过上面的`ContainsKey`方法和`ContainsValue`的源码我们可以很明显的看出：  
　　`Hashtable`中，`key`和`value`都不允许出现`null`值。但是如果在`Hashtable`中有类似`put(null,null)`的操作，编译同样可以通过，因为`key`和`value`都是`Object`类型，但运行时会抛出`NullPointerException`异常，这是JDK的规范规定的。  
　　`HashMap`中，`null`可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为`null`。当`get()`方法返回`null`值时，可能是 `HashMap`中没有该键，也可能使该键所对应的值为`null`。因此，在`HashMap`中不能由`get()`方法来判断`HashMap`中是否存在某个键， 而应该用`containsKey()`方法来判断。

#### 2. 两个遍历方式的内部实现上不同
　　`Hashtable`、`HashMap`都使用了 `Iterator`。而由于历史原因，`Hashtable`还使用了`Enumeration`的方式 。

#### 3. `hash`值不同
　　哈希值的使用不同，`HashTable`直接使用对象的`hashCode`。而`HashMap`重新计算`hash`值。  
　　`hashCode`是jdk根据对象的地址或者字符串或者数字算出来的`int`类型的数值。  
　　`Hashtable`计算`hash`值，直接用`key`的`hashCode()`，而`HashMap`重新计算了`key`的`hash`值，`Hashtable`在求`hash`值对应的位置索引时，用取模运算，
而`HashMap`在求位置索引时，则用与运算，且这里一般先用`hash&0x7FFFFFFF`后，再对`length`取模，`&0x7FFFFFFF`的目的是为了将负的`hash`值转化为正值，因为`hash`值有可能为负数，而`&0x7FFFFFFF`后，只有符号外改变，而后面的位都不变。

#### 4. 内部实现使用的数组初始化和扩容方式不同
　　`Hashtable`和`HashMap`它们两个内部实现方式的数组的初始大小和扩容的方式。
`HashTable`中`hash`数组默认大小是`11`，增加的方式是 `old*2+1`。而`HashMap`为`16`，扩容时，将容量变为原来的`2倍`。 
`Hashtable`不要求底层数组的容量一定要为2的整数次幂，而`HashMap`则要求一定为`2的整数次幂`。  
